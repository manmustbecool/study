## Basic 

* [gradient_descent_and_derivative.ipynb](https://colab.research.google.com/drive/18IfySN0wKFizTiFYf9g0TGxjBFytah_z)

##  LLM

* [llm_tokenizer.ipynb](https://colab.research.google.com/drive/1YXoxLfQ5CXiB0GivAuoe0RR1TVh-Yabe)
  > text input -> tensor -> LLM -> tensor -> text ouput 

* [llm_finetuning_lora.ipynb](https://colab.research.google.com/drive/1Eb8Ry7W3P2XBwhYWltg50z_aLaja2vYb)
  > Fine tuning with PEFT package
  > LoRA Fine tuning
  > Partial Fine-Tuning (Adapter-based or Layer Freezing), applies LoRA to specific layers

* [llm_prompt_tuning.ipynb](https://colab.research.google.com/drive/17UxHuZR7-4CKXqidlhpJEAN6bVG2awGp#scrollTo=OwoxB86g1Frp)

